{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4280167",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "- Built upon previous work [2023-06-30_cleaning_df_bothdata.py](https://github.com/tiangenglu/WebScrape/blob/main/06302023_cleaning_df_bothdata.py)\n",
    "- Detect new raw data and ONLY process the newly scraped data\n",
    "- After cleaning, append to the existing all-time visa data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d34d5",
   "metadata": {},
   "source": [
    "**NOTES**: The program needs minor revisions to read \"old\" data from S3 instead of local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22c7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ee15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retire this chunk\n",
    "# move aws s3 connection up\n",
    "# use niv_alltime and iv_alltime\n",
    "# old_data = pd.read_csv(\"visa_alltime.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b781567",
   "metadata": {},
   "source": [
    "# Accessing scraped raw data in AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e394a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"aws_credential.txt\", 'r') as file:\n",
    "    aws_credential=json.load(file)\n",
    "s3=boto3.Session(\n",
    "    profile_name = None, \n",
    "    region_name = 'us-east-2').client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_credential['access_key'],\n",
    "    aws_secret_access_key=aws_credential['secret_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b7e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_content=s3.list_objects(Bucket = aws_credential['bucket'], Prefix ='visa_output/')['Contents']\n",
    "output_items = [d['Key'].split('/')[-1] for d in output_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38907783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'country_code_matches.csv',\n",
       " 'country_list.txt',\n",
       " 'df_iv.csv',\n",
       " 'df_niv.csv',\n",
       " 'iv_alltime.csv',\n",
       " 'niv_alltime.csv',\n",
       " 'time_iv.txt',\n",
       " 'time_niv.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5a0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_iv_bytes=s3.get_object(Bucket = aws_credential['bucket'], \n",
    "              Key = 'visa_output/time_iv.txt')['Body'].read()\n",
    "time_iv=pd.read_csv(io.BytesIO(time_iv_bytes), delimiter = \"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a90efd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-02-28'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the most recent date\n",
    "time_iv.max()[0] # index 0 to get rid of the series format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab33bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_niv_bytes=s3.get_object(Bucket = aws_credential['bucket'], \n",
    "              Key = 'visa_output/time_niv.txt')['Body'].read()\n",
    "time_niv=pd.read_csv(io.BytesIO(time_niv_bytes), delimiter = \"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca4f2c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent NIV processed: 2025-02-28 \n",
      "Most recent IV processed: 2025-02-28\n"
     ]
    }
   ],
   "source": [
    "print(\"Most recent NIV processed:\",time_niv.max()[0],\"\\nMost recent IV processed:\",time_iv.max()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ad0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_niv_content=s3.list_objects(Bucket = aws_credential['bucket'], Prefix ='messy_data/visa_scraped/niv/')['Contents']\n",
    "bucket_iv_content=s3.list_objects(Bucket = aws_credential['bucket'], Prefix ='messy_data/visa_scraped/iv/')['Contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc8c9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_niv_items=[d['Key'].split('/')[-1] for d in bucket_niv_content]\n",
    "bucket_iv_items=[d['Key'].split('/')[-1] for d in bucket_iv_content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b0f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_iv_date=[f.split('.')[0].split('_')[-1] for f in bucket_iv_items]\n",
    "bucket_niv_date=[f.split('.')[0].split('_')[-1] for f in bucket_niv_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64b33a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent IV scraped: 2025-05-31 \n",
      "Most recent NIV scraped: 2025-05-31\n"
     ]
    }
   ],
   "source": [
    "print(\"Most recent IV scraped:\",bucket_iv_date[-1],\"\\nMost recent NIV scraped:\", bucket_niv_date[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6dab9",
   "metadata": {},
   "source": [
    "# How many months (raw data) need processing? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc0343",
   "metadata": {},
   "source": [
    "**Needs to replace all objects created from `old_data`. 2025-05-09**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81b271b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to append 3 month(s) to existing NIV data.\n"
     ]
    }
   ],
   "source": [
    "# new block to calculate difference in length using time_iv\n",
    "# use a list of time stamps instead of extracting it from the whole dataframe\n",
    "len_diff_niv=len(bucket_niv_items) - len(time_niv)\n",
    "if len_diff_niv > 0:\n",
    "    print(f'Need to append {len_diff_niv} month(s) to existing NIV data.')\n",
    "else: print(\"No actions required, compiled NIV data is up to date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2170f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to append 3 month(s) to existing IV data.\n"
     ]
    }
   ],
   "source": [
    "len_diff_iv=len(bucket_iv_items) - len(time_iv)\n",
    "if len_diff_iv > 0:\n",
    "    print(f'Need to append {len_diff_iv} month(s) to existing IV data.')\n",
    "else: print(\"No actions required, compiled IV data is up to date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4c4fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceed with automation data workflow.\n"
     ]
    }
   ],
   "source": [
    "if len_diff_iv == 0 and len_diff_niv == 0:\n",
    "    print(\"No actions required, compiled NIV and IV data are up to date.\")\n",
    "    sys.exit(0)\n",
    "else: print(\"Proceed with automation data workflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e117d704",
   "metadata": {},
   "source": [
    "**sources for processed and scraped timestamps were replaced as of 2025-07-04**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b5e19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIV needs the following month(s): ['2025-03-31', '2025-04-30', '2025-05-31']\n",
      "IV needs the following month(s): ['2025-03-31', '2025-04-30', '2025-05-31']\n"
     ]
    }
   ],
   "source": [
    "# next, get the list(s) of dates need to be appended\n",
    "niv_date_to_add=bucket_niv_date[-len_diff_niv:]\n",
    "print(f'NIV needs the following month(s): {niv_date_to_add}')\n",
    "iv_date_to_add = bucket_iv_date[-len_diff_iv:]\n",
    "print(f'IV needs the following month(s): {iv_date_to_add}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c1cba",
   "metadata": {},
   "source": [
    "# Read in raw data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ceed7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving single object from bucket\n",
    "#test_object=s3.get_object(Bucket = aws_credential['bucket'], \n",
    "#              Key = 'messy_data/visa_scraped/niv/' + bucket_niv_items[-len_diff_niv])['Body'].read()\n",
    "#type(test_object)\n",
    "# decode\n",
    "#test_object.decode(\"utf-8\").split('\\n')[:5]\n",
    "# put decoded content into a dataframe\n",
    "#pd.DataFrame(test_object.decode(\"utf-8\").split('\\n')).iloc[:5]\n",
    "# the adopted way to read the content in a dataframe\n",
    "#pd.read_csv(io.BytesIO(test_object), delimiter = \"\\t\", header = None).iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de40b2",
   "metadata": {},
   "source": [
    "## Non-immigrant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c72b494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "niv_df_raw = [None] * len_diff_niv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e0d91074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'niv_2025-05-31.txt'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_niv_items[-(0+1)] # print out the last item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad2618fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the -1 item from the .txt folder:\n",
      "Getting the -2 item from the .txt folder:\n",
      "Getting the -3 item from the .txt folder:\n"
     ]
    }
   ],
   "source": [
    "for i in range(len_diff_niv):\n",
    "    print(f'Getting the {-(i+1)} item from the .txt folder:')\n",
    "    file = s3.get_object(Bucket = aws_credential['bucket'],\n",
    "              # offset zero indexing: -(i+1), start from most recent (last in)\n",
    "              Key = 'messy_data/visa_scraped/niv/'+bucket_niv_items[-(i+1)])['Body'].read()\n",
    "    #niv_df_raw[i] = pd.DataFrame(file.decode(\"utf-8\").split('\\n')) # this works\n",
    "    niv_df_raw[i] = pd.read_csv(io.BytesIO(file), delimiter = \"\\t\", header = None) # also works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd925509",
   "metadata": {},
   "source": [
    "## Immigrant visa data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ea74460",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df_raw = [None] * len_diff_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "043dfb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the -1 item from the .txt folder:\n",
      "Getting the -2 item from the .txt folder:\n",
      "Getting the -3 item from the .txt folder:\n"
     ]
    }
   ],
   "source": [
    "for i in range(len_diff_iv):\n",
    "    print(f'Getting the {-(i+1)} item from the .txt folder:')\n",
    "    file = s3.get_object(Bucket = aws_credential['bucket'],\n",
    "              # offset zero indexing: -(i+1), start from most recent (last in)\n",
    "              Key = 'messy_data/visa_scraped/iv/'+bucket_iv_items[-(i+1)])['Body'].read()\n",
    "    #niv_df_raw[i] = pd.DataFrame(file.decode(\"utf-8\").split('\\n')) # this works\n",
    "    iv_df_raw[i] = pd.read_csv(io.BytesIO(file), delimiter = \"\\t\", header = None) # also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20de83d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(iv_df_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f771c",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "If needs re-run this section, revert back to the `(n)iv_df_raw` blocks first!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63ab64",
   "metadata": {},
   "source": [
    "## A list of raw dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13be0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "niv_grand_total = [] # an empty to store grand totals\n",
    "for i in range(len(niv_df_raw)):\n",
    "    niv_df_raw[i].columns = ['V'] # more robust than .rename\n",
    "    # or use .apply(lambda x: x.strip()), but the following is simple\n",
    "    niv_df_raw[i]['V']=niv_df_raw[i]['V'].str.strip().str.upper()\n",
    "    # insert an iterrows() loop to get the index of the grand total row\n",
    "    for idx,row in niv_df_raw[i].iterrows():\n",
    "        if 'grand total'.upper() in row['V']:\n",
    "            niv_grand_total.append(row)\n",
    "            idx_rm_below = idx\n",
    "    niv_df_raw[i]=niv_df_raw[i].iloc[:idx_rm_below]\n",
    "    # offset zero indexing: -(i+1), start from most recent\n",
    "    niv_df_raw[i]['time'] = niv_date_to_add[-(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b2417dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time     total\n",
      "0  2025-03-31    897937\n",
      "1  2025-04-30    993250\n",
      "2  2025-05-31   1006227\n"
     ]
    }
   ],
   "source": [
    "# grand total dataframe\n",
    "gt=pd.DataFrame(niv_grand_total)['V'].str.replace('grand total'.upper(),'').str.replace(',','')\n",
    "niv_total=pd.DataFrame(data={'time':niv_date_to_add,'total':gt}).reset_index(drop = True)\n",
    "del gt\n",
    "print(niv_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "acb7703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_grand_total = []\n",
    "for i in range(len(iv_df_raw)):\n",
    "    iv_df_raw[i].columns = ['V']\n",
    "    iv_df_raw[i]['V']=iv_df_raw[i]['V'].str.strip().str.upper()\n",
    "    for idx,row in iv_df_raw[i].iterrows():\n",
    "        if 'grand total'.upper() in row['V']:\n",
    "            iv_grand_total.append(row)\n",
    "            # index for the grand total row, all rows below grand total will be excluded\n",
    "            idx_rm_below = idx\n",
    "    iv_df_raw[i] = iv_df_raw[i].iloc[:idx_rm_below]\n",
    "    iv_df_raw[i]['time'] = iv_date_to_add[-(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d8d151fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time   total\n",
      "0  2025-03-31   46751\n",
      "1  2025-04-30   48193\n",
      "2  2025-05-31   51574\n"
     ]
    }
   ],
   "source": [
    "# When the loop is completed,create a small dataframe to store monthly grand totals\n",
    "gt=pd.DataFrame(iv_grand_total)['V'].str.replace('grand total'.upper(),'').str.replace(',','')\n",
    "iv_total=pd.DataFrame(data={'time':iv_date_to_add,'total':gt}).reset_index(drop = True)\n",
    "del gt\n",
    "print(iv_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d5f5b6",
   "metadata": {},
   "source": [
    "## Concatenated one long dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1994ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_niv=pd.concat([df for df in niv_df_raw])\n",
    "df_niv = df_raw_niv.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c4e57404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_iv=pd.concat([df for df in iv_df_raw])\n",
    "df_iv=df_raw_iv.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067e963",
   "metadata": {},
   "source": [
    "## Remove non-data rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa8677",
   "metadata": {},
   "source": [
    "### NIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d1541072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NONIMMIGRANT|NATIONALITY VISA|\\\\(FY|\\\\#SBU|PAGE|SENSITIVE'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "niv_headers = ['NONIMMIGRANT','NATIONALITY VISA','\\\\(FY', '\\\\#SBU','PAGE','SENSITIVE']\n",
    "'|'.join([h for h in niv_headers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1914ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_niv[df_niv['V'].str.len() <=1]\n",
    "df_niv_headers=df_niv[df_niv['V'].str.contains('|'.join(niv_headers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0dd5bb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   0,   42,   43,   44,   45,   46,   89,   90,   91,  134,\n",
       "       ...\n",
       "       3691, 3734, 3735, 3736, 3779, 3780, 3781, 3824, 3825, 3826],\n",
       "      dtype='int64', length=774)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_niv_headers.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9b27ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows that were headers & footers, not final yet\n",
    "df_niv=df_niv.iloc[~df_niv.index.isin(df_niv_headers.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e865b2",
   "metadata": {},
   "source": [
    "### IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bcf7fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv['V'] = df_iv['V'].str.strip()\n",
    "df_iv = df_iv[df_iv['V'].str.len() > 1]\n",
    "iv_headers = ['PAGE ', 'FOREIGN STATE OF', 'CHARGEABILITY', \n",
    "              'PLACE OF BIRTH', '\\\\(FY 20', '\\\\(FY20',\n",
    "              'IMMIGRANT VISA', 'SENSITIVE']\n",
    "df_iv_headers = df_iv.loc[df_iv['V'].str.contains('|'.join(iv_headers))]\n",
    "df_iv = df_iv.iloc[~df_iv.index.isin(df_iv_headers.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f2638bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iv_headers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a56e4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4819, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cff598",
   "metadata": {},
   "source": [
    "## Split all-in-one column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c72bc",
   "metadata": {},
   "source": [
    "### NIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "827d8440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFGHANISTAN B1/B2 67</td>\n",
       "      <td>2025-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFGHANISTAN E2 1</td>\n",
       "      <td>2025-05-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      V        time\n",
       "1  AFGHANISTAN B1/B2 67  2025-05-31\n",
       "2      AFGHANISTAN E2 1  2025-05-31"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_niv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a2ffa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the warning messages\n",
    "pd.options.mode.copy_on_write = True\n",
    "df_niv['nationality']=[' '.join(row.split(' ')[:-2]).strip() for row in df_niv['V']]\n",
    "# visa class\n",
    "df_niv['visa']=[row.split(' ')[-2].strip() for row in df_niv['V']]\n",
    "# remove thousand separator , from numbers\n",
    "df_niv['issue']=[row.split(' ')[-1].replace(',','').strip() for row in df_niv['V']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a63d5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>time</th>\n",
       "      <th>nationality</th>\n",
       "      <th>visa</th>\n",
       "      <th>issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFGHANISTAN B1/B2 67</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>B1/B2</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFGHANISTAN E2 1</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>E2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      V        time  nationality   visa issue\n",
       "1  AFGHANISTAN B1/B2 67  2025-05-31  AFGHANISTAN  B1/B2    67\n",
       "2      AFGHANISTAN E2 1  2025-05-31  AFGHANISTAN     E2     1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_niv.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3596003",
   "metadata": {},
   "source": [
    "### IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e6d23b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv['nationality']=[' '.join(row.split(' ')[:-2]).strip() for row in df_iv['V']]\n",
    "df_iv['visa']=[row.split(' ')[-2].strip() for row in df_iv['V']]\n",
    "df_iv['issue']=[row.split(' ')[-1].replace(',','').strip() for row in df_iv['V']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "39da499b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>time</th>\n",
       "      <th>nationality</th>\n",
       "      <th>visa</th>\n",
       "      <th>issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFGHANISTAN CR1 34</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>CR1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFGHANISTAN CR2 1</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>CR2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    V        time  nationality visa issue\n",
       "2  AFGHANISTAN CR1 34  2025-05-31  AFGHANISTAN  CR1    34\n",
       "3   AFGHANISTAN CR2 1  2025-05-31  AFGHANISTAN  CR2     1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iv.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53445ebb",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fee94b",
   "metadata": {},
   "source": [
    "## Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test list comprehension with a short and simple list\n",
    "[s for s in ['34',23,'a1','20','b '] if not str(s).isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d38179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there non-numeric values in the visa issuance count column?\n",
    "check_numeric=[s for s in df_niv['issue'] if not str(s).isdigit()]\n",
    "if len(check_numeric)>0:\n",
    "    print(\"At least one row has non-numeric values in the NIV issuance column. Go back and check.\")\n",
    "    print(check_numeric)\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"No non-numeric values were detected in the NIV issuance column. Good to proceed.\")\n",
    "    df_niv['issue'] = df_niv['issue'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there non-numeric values in the visa issuance count column?\n",
    "check_numeric=[s for s in df_iv['issue'] if not str(s).isdigit()]\n",
    "if len(check_numeric)>0:\n",
    "    print(\"At least one row has non-numeric values in the IV issuance column. Go back and check.\")\n",
    "    print(check_numeric)\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"No non-numeric values were detected in the IV issuance column. Good to proceed.\")\n",
    "    df_iv['issue'] = df_iv['issue'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2bb20",
   "metadata": {},
   "source": [
    "## Restoring rows when data got mixed with headers\n",
    "\n",
    "- This is the most challenging part of cleaning this dataset.\n",
    "- `if any(pattern in input_text for pattern in pattern_list):`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efcc15",
   "metadata": {},
   "source": [
    "### NIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b621e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_idx = []\n",
    "# here's how any() works\n",
    "for idx,row in df_niv_headers.iterrows():\n",
    "    if any(c in row['V'] for c in df_niv.nationality.unique()):\n",
    "        print(idx, row)\n",
    "        restore_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecdaf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restore=df_niv_headers.loc[restore_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ff794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restore['nationality']=[' '.join(row.split('NONIMMIGRANT')[0].strip().split(' ')[:-2]).strip() for row in df_restore['V']]\n",
    "df_restore['visa'] = [row.split('NONIMMIGRANT')[0].strip().split(' ')[-2].strip() for row in df_restore['V']]\n",
    "df_restore['issue'] = [row.split('NONIMMIGRANT')[0].strip().split(' ')[-1].strip().replace(',','') for row in df_restore['V']]\n",
    "df_restore['issue'] = df_restore['issue'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b80d2ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_restore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373f928",
   "metadata": {},
   "source": [
    "### IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_idx_iv = []\n",
    "# here's how any() works\n",
    "for idx,row in df_iv_headers.iterrows():\n",
    "    if any(c in row['V'] for c in df_iv.nationality.unique()):\n",
    "        print(idx, row)\n",
    "        restore_idx_iv.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restore_iv=df_iv_headers.loc[restore_idx_iv]\n",
    "df_restore_iv['nationality']=[' '.join(row.split('IMMIGRANT')[0].strip().split(' ')[:-2]).strip() for row in df_restore_iv['V']]\n",
    "df_restore_iv['visa'] = [row.split('IMMIGRANT')[0].strip().split(' ')[-2].strip() for row in df_restore_iv['V']]\n",
    "df_restore_iv['issue'] = [row.split('IMMIGRANT')[0].strip().split(' ')[-1].strip().replace(',','') for row in df_restore_iv['V']]\n",
    "df_restore_iv['issue'] = df_restore_iv['issue'].astype(int)\n",
    "df_restore_iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d47d0c",
   "metadata": {},
   "source": [
    "## Concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['nationality', 'visa', 'issue','time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_niv=pd.concat([df_niv, df_restore]).sort_index().drop(columns = ['V'])[col_order].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98760228",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grand_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_niv['issue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv=pd.concat([df_iv, df_restore_iv]).sort_index().drop(columns=['V'])[col_order].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b174427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv['issue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_niv = df_niv.rename(columns={'issue':'count'})\n",
    "df_iv = df_iv.rename(columns={'issue':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb533a71",
   "metadata": {},
   "source": [
    "# Appending to existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92935a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "niv_alltime=s3.get_object(Bucket = aws_credential['bucket'], \n",
    "              Key = 'visa_output/niv_alltime.csv')['Body'].read()\n",
    "df_niv_alltime = pd.read_csv(io.BytesIO(niv_alltime),low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_alltime=s3.get_object(Bucket = aws_credential['bucket'], \n",
    "              Key = 'visa_output/iv_alltime.csv')['Body'].read()\n",
    "df_iv_alltime = pd.read_csv(io.BytesIO(iv_alltime),low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_niv_alltime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_alltime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefcf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_niv_alltime_new=pd.concat([df_niv_alltime, df_niv]).reset_index(drop=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7289ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iv_alltime_new=pd.concat([df_iv_alltime, df_iv]).reset_index(drop=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efab8df",
   "metadata": {},
   "source": [
    "# Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee653f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list=list(set(list(df_iv_alltime_new['nationality'].unique()) + \n",
    "                      list(df_niv_alltime_new['nationality'].unique()\n",
    "                          )\n",
    "                     )\n",
    "                 )\n",
    "print(\"Total unique country/nationality labels before cleaning: \",len(country_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars = []\n",
    "# instead of iterrows, can also work on a list of unique nationalities\n",
    "for country in country_list:\n",
    "    for char in country:\n",
    "        if not (char.isalpha() or char == ' '):\n",
    "            if char not in special_chars:\n",
    "                special_chars.append(char)\n",
    "                print(char, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7779daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars.remove(',') # potential legit\n",
    "special_chars.remove(\"'\") # potential legit\n",
    "special_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_country_label = []\n",
    "new_country_label = []\n",
    "for country in country_list:\n",
    "    # the following covers the case when one string contains multiple special characters: e.g., '(' and ')'\n",
    "    if any(char in country for char in special_chars):\n",
    "        # if it's a letter or a space, join as usual, then replace special character with a space\n",
    "        new_country = ''.join([char if (char.isalpha() or char == ' ') \n",
    "                               else char.replace(char,' ') \n",
    "                               for char in country]) # replace special character with space\n",
    "        new_country = ' '.join(new_country.split()).replace('BORN','').strip() # split() to remove excessive space\n",
    "        old_country_label.append(country)\n",
    "        new_country_label.append(new_country)\n",
    "        print(\"\\nold: \",country,'\\nnew: ', new_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65231b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_sp_char_label=dict(zip(old_country_label,new_country_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map new country labels to a new column nationality2, then replace it with original nationality\n",
    "df_niv_alltime_new['nationality2'] = df_niv_alltime_new['nationality'].map(\n",
    "    no_sp_char_label).fillna(\n",
    "    df_niv_alltime_new['nationality'])\n",
    "df_iv_alltime_new['nationality2'] = df_iv_alltime_new['nationality'].map(\n",
    "    no_sp_char_label).fillna(\n",
    "    df_iv_alltime_new['nationality'])\n",
    "df_niv_alltime_new = df_niv_alltime_new.drop(\n",
    "    columns=['nationality']).rename(\n",
    "    columns={'nationality2':'nationality'})\n",
    "df_iv_alltime_new = df_iv_alltime_new.drop(\n",
    "    columns=['nationality']).rename(\n",
    "    columns={'nationality2':'nationality'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list_new=list(set(list(df_iv_alltime_new['nationality'].unique()) + \n",
    "                      list(df_niv_alltime_new['nationality'].unique()\n",
    "                          )\n",
    "                     )\n",
    "                 )\n",
    "print(\"Total unique country/nationality labels after cleaning: \",len(country_list_new))\n",
    "print(f'After removing special characters, {len(country_list) - len(country_list_new)} labels were reduced.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb3feb",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3caad2",
   "metadata": {},
   "source": [
    "## Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f763ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('country_list.txt','w') as file:\n",
    "    file.write('\\n'.join(country_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['nationality','visa', 'count', 'time']\n",
    "df_niv_alltime_new = df_niv_alltime_new[new_col_order]\n",
    "df_iv_alltime_new = df_iv_alltime_new[new_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c10dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_niv=list(df_niv_alltime_new['time'].unique())\n",
    "time_iv=list(df_iv_alltime_new['time'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output a list of time stamps\n",
    "with open('time_niv.txt', 'w') as file:\n",
    "    file.write('\\n'.join(time_niv))\n",
    "with open('time_iv.txt', 'w') as file:\n",
    "    file.write('\\n'.join(time_iv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826d6568",
   "metadata": {},
   "source": [
    "## S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list a string to upload\n",
    "s3.put_object(Body = \"\\n\".join([c for c in country_list_new]), \n",
    "              Bucket = aws_credential['bucket'], \n",
    "              Key = 'visa_output/country_list.txt')\n",
    "s3.put_object(Body = \"\\n\".join([t for t in time_niv]), \n",
    "              Bucket = aws_credential['bucket'], \n",
    "              Key = 'visa_output/time_niv.txt')\n",
    "s3.put_object(Body = \"\\n\".join([t for t in time_iv]), \n",
    "              Bucket = aws_credential['bucket'], \n",
    "              Key = 'visa_output/time_iv.txt')\n",
    "# list objects after upload\n",
    "output_folder_items=s3.list_objects(Bucket = aws_credential['bucket'], Prefix = 'visa_output')['Contents']\n",
    "item_names=[d['Key'] for d in output_folder_items]\n",
    "[item for item in item_names if item.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffec44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload pandas dataframe to s3\n",
    "csv_buffer = io.StringIO()\n",
    "df_niv_alltime_new.to_csv(csv_buffer, index=False)\n",
    "s3.put_object(Body = csv_buffer.getvalue(), \n",
    "              Bucket = aws_credential['bucket'], \n",
    "              Key = 'visa_output/df_niv.csv')\n",
    "# create a new csv buffer object to upload a different data frame\n",
    "csv_buffer = io.StringIO()\n",
    "df_iv_alltime_new.to_csv(csv_buffer, index=False)\n",
    "s3.put_object(Body = csv_buffer.getvalue(), \n",
    "              Bucket = aws_credential['bucket'], \n",
    "              Key = 'visa_output/df_iv.csv')\n",
    "# list objects after upload\n",
    "output_folder_items=s3.list_objects(Bucket = aws_credential['bucket'], Prefix = 'visa_output')['Contents']\n",
    "item_names=[d['Key'] for d in output_folder_items]\n",
    "[item for item in item_names if item.endswith('.csv')]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py-3-12-3-preview",
   "language": "python",
   "name": "python-312-preview"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
